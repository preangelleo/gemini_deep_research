# ==================================================================
# GEMINI DEEP RESEARCH AGENT - ENVIRONMENT CONFIGURATION
# ==================================================================
# This is an example configuration file. Copy this to .env and fill in your values.
# DO NOT commit your actual .env file with real API keys to version control!

# ------------------------------------------------------------------
# GEMINI API CONFIGURATION
# ------------------------------------------------------------------

# Required: Your Google Gemini API key from https://ai.google.dev/
# Get your free API key at Google AI Studio
GEMINI_API_KEY=your_gemini_api_key_here

# Default model to use for research and report generation
# Options: gemini-2.5-pro, gemini-2.5-flash, gemini-1.5-pro, gemini-1.5-flash
# Recommendation: Use gemini-2.5-pro for best results (default)
GEMINI_MODEL=gemini-2.5-pro

# Alternative model for lightweight tasks (optional)
# Use Flash for faster, cheaper operations like keyword extraction
GEMINI_FLASH_MODEL=gemini-2.5-flash

# ------------------------------------------------------------------
# GOOGLE SEARCH CONFIGURATION
# ------------------------------------------------------------------

# Maximum number of search queries per research task
# Cost: $35 per 1,000 searches = $0.035 per search
# Default: 10 searches = ~$0.35 per task
# You can increase this for more comprehensive research (cost increases accordingly)
MAX_SEARCHES_PER_TASK=10

# Search result limit per query (how many URLs to consider from each search)
SEARCH_RESULTS_PER_QUERY=10

# Enable Google Search grounding tool (true/false)
# This uses Gemini's built-in search capabilities
ENABLE_GOOGLE_SEARCH_GROUNDING=true

# ------------------------------------------------------------------
# WEB CRAWLING CONFIGURATION (CRAWL4AI)
# ------------------------------------------------------------------

# Maximum number of URLs to crawl simultaneously in parallel
# Higher numbers = faster processing but more resource usage
# Recommended: 5-20 depending on your system capabilities
MAX_CONCURRENT_CRAWLS=10

# Timeout for each individual URL crawl (in seconds)
# If a website takes longer than this, skip it and move on
CRAWL_TIMEOUT_PER_URL=30

# Maximum total timeout for entire crawling phase (in minutes)
# After this time, use whatever content we've collected so far
MAX_CRAWL_TIMEOUT_MINUTES=5

# Maximum content length to extract per URL (in characters)
# Helps prevent memory issues with very large pages
MAX_CONTENT_LENGTH_PER_URL=50000

# ------------------------------------------------------------------
# TOKEN AND CONTEXT MANAGEMENT
# ------------------------------------------------------------------

# Gemini Context Window Limits (Update these based on Google's latest specs)
# Current as of January 2025 - Gemini 2.5 Pro specifications
GEMINI_INPUT_CONTEXT_LIMIT=1000000    # 1M tokens input context window
GEMINI_OUTPUT_CONTEXT_LIMIT=8192      # 8K tokens maximum output per response
GEMINI_TOTAL_CONTEXT_LIMIT=1000000    # Total context window size

# Legacy compatibility (will be deprecated)
GEMINI_CONTEXT_LIMIT=900000

# Token Budget Allocation
RESERVED_TOKENS_FOR_REPORT=100000     # Reserve tokens for final report generation
TOKEN_SAFETY_BUFFER=50000             # Safety buffer to prevent context overflow
MAX_TOTAL_TOKENS=800000               # Stop crawling if content exceeds this

# Token Counting Configuration
# Rough estimate: 1 token â‰ˆ 4 characters for English text
# Set to 'true' to use more accurate tiktoken library (if available)
USE_ACCURATE_TOKEN_COUNTING=true

# Token estimation method: "auto", "tiktoken", "character", "word"
TOKEN_COUNTING_METHOD=auto

# ------------------------------------------------------------------
# PERFORMANCE AND OPTIMIZATION
# ------------------------------------------------------------------

# Enable async/await processing for maximum efficiency
ENABLE_ASYNC_PROCESSING=true

# Enable parallel processing for URL crawling
ENABLE_PARALLEL_CRAWLING=true

# Number of worker threads for concurrent operations
# Recommendation: Number of CPU cores * 2
WORKER_THREAD_COUNT=8

# Enable request caching to avoid duplicate searches/crawls
ENABLE_REQUEST_CACHING=true

# Cache expiration time (in hours)
CACHE_EXPIRATION_HOURS=24

# ------------------------------------------------------------------
# CONTENT FILTERING AND QUALITY
# ------------------------------------------------------------------

# Minimum content length to consider (filters out very short pages)
MIN_CONTENT_LENGTH=500

# Minimum legitimate content length (detects paywall/verification pages)
# If content is shorter than this, likely blocked by paywall or verification
MIN_LEGITIMATE_CONTENT_LENGTH=800

# Paywall URL blacklist (comma-separated list of URL prefixes to skip)
# URLs starting with these will be automatically skipped without crawling
PAYWALL_URL_BLACKLIST=wsj.com,nytimes.com,ft.com,bloomberg.com,economist.com,washingtonpost.com,newyorker.com,wired.com,theatlantic.com,harpers.org,vanityfair.com,nationalreview.com,foreignaffairs.com,mp.weixin.qq.com/s/,medium.com/@,substack.com

# AI Content Polishing and Report Generation
# Set to false to disable, true for basic polishing, 2 for comprehensive report generation
AI_POLISH_CONTENT=false

# Model to use for AI polishing (uses more advanced model for better results)
AI_POLISH_MODEL=gemini-2.5-pro

# Maximum tokens for the final polished report (Gemini 2.5 Pro max: 64,000)
# Recommended: 32000 for comprehensive reports, 8000 for basic polishing
MAX_POLISH_REPORT_TOKENS=32000

# Maximum content length per source (prevents processing huge documents)
MAX_CONTENT_LENGTH=100000

# Skip non-text content types (images, videos, etc.)
SKIP_NON_TEXT_CONTENT=true

# Language filter (empty = all languages, or specify like 'en,es,fr')
LANGUAGE_FILTER=

# ------------------------------------------------------------------
# OUTPUT AND REPORTING
# ------------------------------------------------------------------

# Output format for research reports
# Options: markdown, html, json, txt
DEFAULT_OUTPUT_FORMAT=markdown

# Include source citations in reports
INCLUDE_CITATIONS=true

# Include confidence scores for information
INCLUDE_CONFIDENCE_SCORES=false

# Maximum report length (in characters)
MAX_REPORT_LENGTH=20000

# ------------------------------------------------------------------
# DEVELOPMENT AND DEBUGGING
# ------------------------------------------------------------------

# Enable verbose logging for debugging
DEBUG_MODE=false

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Save intermediate results (search results, crawled content, etc.)
SAVE_INTERMEDIATE_RESULTS=false

# Directory to save debug/intermediate files
DEBUG_OUTPUT_DIR=./debug_output

# ------------------------------------------------------------------
# RATE LIMITING AND SAFETY
# ------------------------------------------------------------------

# Delay between API requests (in seconds) to avoid rate limiting
API_REQUEST_DELAY=0.1

# Maximum retries for failed requests
MAX_RETRIES=3

# Exponential backoff multiplier for retries
RETRY_BACKOFF_MULTIPLIER=2

# User agent string for web crawling
USER_AGENT="Gemini_DeepResearch_Bot/1.0 (+https://github.com/yourusername/gemini_deep_research)"

# ------------------------------------------------------------------
# COST TRACKING AND LIMITS
# ------------------------------------------------------------------

# Maximum cost per research task (in USD)
# This helps prevent runaway costs
MAX_COST_PER_TASK=5.00

# Track and log estimated costs
ENABLE_COST_TRACKING=true

# Alert threshold for high costs (in USD)
COST_ALERT_THRESHOLD=10.00

# ------------------------------------------------------------------
# OPTIONAL: ADVANCED FEATURES
# ------------------------------------------------------------------

# Enable experimental features (may be unstable)
ENABLE_EXPERIMENTAL_FEATURES=false

# Use local embedding models for similarity scoring (requires additional setup)
USE_LOCAL_EMBEDDINGS=false

# Enable result ranking and relevance scoring
ENABLE_RESULT_RANKING=true

# Enable automatic keyword expansion
ENABLE_KEYWORD_EXPANSION=true

# ------------------------------------------------------------------
# EXAMPLE VALUES FOR DIFFERENT USE CASES
# ------------------------------------------------------------------

# BUDGET-CONSCIOUS SETUP (Lower costs):
# MAX_SEARCHES_PER_TASK=5
# MAX_CONCURRENT_CRAWLS=5
# GEMINI_MODEL=gemini-2.5-flash

# COMPREHENSIVE RESEARCH SETUP (Higher quality):
# MAX_SEARCHES_PER_TASK=20
# MAX_CONCURRENT_CRAWLS=15
# GEMINI_MODEL=gemini-2.5-pro

# DEVELOPMENT/TESTING SETUP:
# MAX_SEARCHES_PER_TASK=3
# MAX_CONCURRENT_CRAWLS=3
# DEBUG_MODE=true
# SAVE_INTERMEDIATE_RESULTS=true